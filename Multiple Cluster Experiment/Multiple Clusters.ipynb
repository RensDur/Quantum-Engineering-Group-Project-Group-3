{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering - 4 Clusters\n",
    "\n",
    "# Note\n",
    "This is not the final version of this feature, for the more refined version go to \"Multifeature Experiment/MultifeatureExperiment.ipynb\"\n",
    "\n",
    "### DataPoint\n",
    "First, we'll have to create a DataPoint class, that can be used to store and compare input-datapoints. We'll do this as follows, including a ```dist``` function to compute the squared-distance between two datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import is required in python version < 3.11 to allos reference to DataPoint inside definition of DataPoint\n",
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def sqr(x: float):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "class DataPoint:\n",
    "    x: float\n",
    "    y: float\n",
    "    cluster: int\n",
    "    fidelity: float\n",
    "\n",
    "    def __init__(self, x: float, y: float):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.cluster = 0\n",
    "        self.fidelity = 0\n",
    "\n",
    "    def dist(self, o: DataPoint) -> float:\n",
    "        return sqr(o.x - self.x) + sqr(o.y - self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also implement the ```map``` function, that can be used to map Data Points onto the Bloch Sphere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(a: float, b: float, c: float, d: float, e: float) -> float:\n",
    "    return d + ((a - b)/(c - b)) * (e - d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qiskit\n",
    "Now, we start working with Qiskit! Import all the necessary elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit.providers.aer import Aer\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix\n",
    "from qiskit import transpile\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.algorithms.optimizers import ADAM\n",
    "from qiskit.algorithms.optimizers import GradientDescent\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the np random seed\n",
    "np.random.seed(12)\n",
    "\n",
    "#\n",
    "# Hard-code the data points that the algorithm will be performed on\n",
    "#\n",
    "x_range = iris.data[:, 1]\n",
    "y_range = iris.data[:, 3]\n",
    "data_points = []\n",
    "\n",
    "min_x = 2\n",
    "max_x = 4.4\n",
    "\n",
    "min_y = 0.1\n",
    "max_y = 2.5\n",
    "\n",
    "alpha = 1\n",
    "lamda = 0.1\n",
    "\"\"\"\n",
    "points_0 = [DataPoint(np.random.uniform(low=0, high=20),\n",
    "                      np.random.uniform(low=0, high=20)) for i in range(10)]\n",
    "\n",
    "points_1 = [DataPoint(np.random.uniform(low=30, high=50),\n",
    "                      np.random.uniform(low=0, high=20)) for i in range(10)]\n",
    "\n",
    "points_2 = [DataPoint(np.random.uniform(low=0, high=20),\n",
    "                      np.random.uniform(low=30, high=50)) for i in range(10)]\n",
    "\n",
    "points_3 = [DataPoint(np.random.uniform(low=30, high=50),\n",
    "                      np.random.uniform(low=30, high=50)) for i in range(10)]\n",
    "\"\"\"\n",
    "for l in range(len(x_range)):\n",
    "    data_points.append(DataPoint(x_range[l], y_range[l]))\n",
    "\n",
    "\n",
    "# Plot the datapoints\n",
    "plt.title(\"Input Data Points\")\n",
    "plt.scatter(\n",
    "    [dp.x for dp in data_points],\n",
    "    [dp.y for dp in data_points]\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Hard-code the two reference states on the bloch-sphere that we will use as references for two clusters\n",
    "#\n",
    "# [1, 0] = |0> and [0, 1] = |1>\n",
    "reference_points = [\n",
    "    Statevector([1, 0, 0, 0]), # 0-0\n",
    "    Statevector([0, 1, 0, 0]), # 0-1\n",
    "    Statevector([0, 0, 1, 0]), # 1-0\n",
    "    #Statevector([0, 0, 0, 1]), # 1-1\n",
    "]\n",
    "\n",
    "circuit_counter = 0\n",
    "# Function: setup the variational form according to given parameters\n",
    "def setup_var_form(dp: DataPoint, params, qubits = 2) -> QuantumCircuit:\n",
    "    global circuit_counter\n",
    "    \n",
    "    q_circuit = QuantumCircuit(qubits)\n",
    "    q_circuit.name = \"circuit\" + str(circuit_counter)\n",
    "    circuit_counter += 1\n",
    "    \n",
    "    # Initialize both qubits in state zero\n",
    "    q_circuit.initialize([1, 0], 0)\n",
    "    q_circuit.initialize([1, 0], 1)\n",
    "    \n",
    "    # Unitary transformations that insert data-point properties\n",
    "    for i in range(qubits):\n",
    "        x_map = map(dp.x, min_x, max_x, 0, math.pi)\n",
    "        y_map = map(dp.y, min_y, max_y, 0, math.pi)\n",
    "        q_circuit.u(x_map,\n",
    "                    y_map, x_map * y_map, i) # data-point[x] on qubit 1 as x-transformation\n",
    "    \n",
    "    # Create entanglement between the two qubits\n",
    "    #q_circuit.h(0)\n",
    "    #q_circuit.cnot(0, 1)\n",
    "    \n",
    "    # Unitary transformations for optimization parameters\n",
    "    for i in range(qubits-1):\n",
    "        q_circuit.u(params[2*i], params[2*i+1], 0, i) # Parameters 0 and 1 on qubit 0\n",
    "        q_circuit.cnot(i, i+1)\n",
    "    q_circuit.u(params[2*qubits-2], params[2*qubits-1], 0, qubits-1) # Parameters 2 and 3 on qubit 1\n",
    "    \n",
    "    q_circuit.save_statevector()\n",
    "    \n",
    "#     print(\"Quantum Circuit:\")\n",
    "#     print(q_circuit)\n",
    "    \n",
    "    return q_circuit\n",
    "\n",
    "#setup_variational_form(DataPoint(0, 5), [1, 2, 3, 4])\n",
    "\n",
    "\n",
    "\n",
    "# Objective function\n",
    "def objective(params) -> float:\n",
    "    #print(\"Running objective...\")\n",
    "    \n",
    "    total_cost = 0\n",
    "    \n",
    "    # Select the qiskit backend\n",
    "    qiskit_backend = Aer.get_backend(\"aer_simulator\")\n",
    "    \n",
    "    cache = []\n",
    "    fidelities = [[None for i in range(len(data_points))] for j in range(len(reference_points))]\n",
    "    centroids = [DataPoint(0, 0) for i in range(len(reference_points))]\n",
    "    counts = [0 for i in range(len(reference_points))]\n",
    "    \n",
    "    for i in range(len(data_points)):\n",
    "        cache.append(None)\n",
    "    \n",
    "    for i in tqdm(range(len(data_points))):\n",
    "        #print(\"\\tConsidering point [\" + str(i) + \", \" + str(j) + \"]\")\n",
    "        # Compute the fidelity\n",
    "        job_dp1 = cache[i]\n",
    "                \n",
    "        if job_dp1 == None:\n",
    "            job_dp1 = qiskit_backend.run(\n",
    "                transpile(\n",
    "                    setup_var_form(data_points[i], params),\n",
    "                    backend=qiskit_backend\n",
    "                )\n",
    "            ).result().get_statevector()\n",
    "            cache[i] = job_dp1\n",
    "                \n",
    "            # Compute fidelities with reference points\n",
    "            data_points[i].fidelity = 0\n",
    "            for ref_index, r in enumerate(reference_points):\n",
    "                # Add the input-set-distance to the cost\n",
    "                    \n",
    "                if (fidelities[ref_index][i] == None):\n",
    "                    fidelities[ref_index][i] = state_fidelity(r, job_dp1)\n",
    "                fidelity_state1 = fidelities[ref_index][i]\n",
    "                    \n",
    "                if (fidelity_state1 > data_points[i].fidelity):\n",
    "                    data_points[i].cluster = ref_index\n",
    "                    data_points[i].fidelity = fidelity_state1\n",
    "                    \n",
    "        penalty = 0\n",
    "        for r in range(len(reference_points)):\n",
    "            penalty += fidelities[r][i] - 1\n",
    "        total_cost += penalty ** 2\n",
    "    \n",
    "    for dp in data_points:\n",
    "        centroids[dp.cluster].x += dp.x\n",
    "        centroids[dp.cluster].y += dp.y\n",
    "        counts[dp.cluster] += 1\n",
    "    \n",
    "    for i in range(len(reference_points)):\n",
    "        if (counts[i] > 0):\n",
    "            centroids[i].x = centroids[i].x / counts[i]\n",
    "            centroids[i].y = centroids[i].y / counts[i]\n",
    "    \n",
    "    for i in range(len(data_points)):\n",
    "        centroid_distance = data_points[i].dist(centroids[data_points[i].cluster])\n",
    "        for j in range(len(data_points)):\n",
    "            cost = data_points[i].dist(data_points[j]) ** alpha\n",
    "            cost += centroid_distance * lamda\n",
    "            sum_fidels = 0\n",
    "            for r in range(len(reference_points)):\n",
    "                sum_fidels += (1-fidelities[r][i])*(1-fidelities[r][j])\n",
    "            cost *= sum_fidels\n",
    "            total_cost += cost\n",
    "        \n",
    "    print(\"Total cost: \" + str(total_cost))\n",
    "    return total_cost\n",
    "            \n",
    "# Select the right optimizer\n",
    "optimizer = ADAM(maxiter=30, tol=10^-6, lr=0.05)\n",
    "# optimizer = GradientDescent(maxiter=10)\n",
    "\n",
    "# Initialize the parameters with random values\n",
    "params_init = np.random.rand(4)\n",
    "\n",
    "# Perform the optimization and store the result\n",
    "optimal_params = optimizer.minimize(fun=objective, x0=params_init).x\n",
    "\n",
    "print(optimal_params)\n",
    "print(\"Total cost: \" + str(objective(optimal_params)))\n",
    "\n",
    "# Divide the points into clusters, according to the information that's stored within the datapoints\n",
    "clusters = []\n",
    "\n",
    "for ref_index in range(len(reference_points)):\n",
    "    current_cluster = []\n",
    "    for dp in data_points:\n",
    "        if ref_index == dp.cluster:\n",
    "            current_cluster.append(dp)\n",
    "    clusters.append(current_cluster)\n",
    "    \n",
    "for c in clusters:\n",
    "    plt.scatter(\n",
    "        [dp.x for dp in c],\n",
    "        [dp.y for dp in c]\n",
    "    )\n",
    "plt.title(\"Clusters after optimizing\")\n",
    "plt.show()\n",
    "\n",
    "for i, c in enumerate(clusters):\n",
    "    print(\"Data Points in cluster \" + str(i) + \":\")\n",
    "    for dp in c:\n",
    "        print(\"[\" + str(dp.x) + \", \" + str(dp.y) + \"]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
