{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering using VQE\n",
    "\n",
    "### DataPoint\n",
    "First, we'll have to create a DataPoint class, that can be used to store and compare input-datapoints. We'll do this as follows, including a ```dist``` function to compute the squared-distance between two datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def sqr(x: float):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataPoint:\n",
    "    x: float\n",
    "    y: float\n",
    "    cluster: int = 0\n",
    "    original_cluster: int = 0\n",
    "    fidelity: float = 0.0\n",
    "\n",
    "    def dist(self, o: \"DataPoint\") -> float:\n",
    "        return abs(o.x - self.x) + abs(o.y - self.y)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Dataset:\n",
    "    _clusters: List[List[DataPoint]]\n",
    "    min_x: int = 0\n",
    "    max_x: int = 0\n",
    "    min_y: int = 0\n",
    "    max_y: int = 0\n",
    "    _complete = None\n",
    "\n",
    "    cached_distance_matrix = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.complete_dataset)\n",
    "\n",
    "    @property\n",
    "    def accuracy(self) -> float:\n",
    "        # Accuracy metric: Correctly classified to the initial cluster / total\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for cluster in self._clusters:\n",
    "            for point in cluster:\n",
    "                total += 1\n",
    "                if point.original_cluster == point.cluster:\n",
    "                    correct += 1\n",
    "\n",
    "        return correct / total\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.complete_dataset[item]\n",
    "\n",
    "    @property\n",
    "    def complete_dataset(self) -> List[DataPoint]:\n",
    "        if self._complete is not None:\n",
    "            return self._complete\n",
    "\n",
    "        # normalize clusters\n",
    "        for i in self._clusters:\n",
    "            for j in i:\n",
    "                j.x = (j.x - self.min_x) / (self.max_x - self.min_x)\n",
    "                j.y = (j.y - self.min_y) / (self.max_y - self.min_y)\n",
    "        # Compute the complete dataset and cache it\n",
    "        self._complete = [point for cluster in self._clusters for point in cluster]\n",
    "        return self._complete\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_clusters(**kwargs) -> \"Dataset\":\n",
    "        clusters = []\n",
    "\n",
    "        min_x = np.inf\n",
    "        min_y = np.inf\n",
    "\n",
    "        max_x = -np.inf\n",
    "        max_y = -np.inf\n",
    "\n",
    "        for i in range(1, kwargs.get(\"clusters\", 2) + 1):\n",
    "            current_cluster = []\n",
    "            # Load cluster parameters\n",
    "            cluster_angle_start = kwargs.get(f\"cluster_{i}_angle_start\", 0)\n",
    "            cluster_angle_end = kwargs.get(f\"cluster_{i}_angle_end\", 360)\n",
    "            cluster_center_x = kwargs.get(f\"cluster_{i}_center_x\", 0)\n",
    "            cluster_center_y = kwargs.get(f\"cluster_{i}_center_y\", 0)\n",
    "            cluster_radius_start = kwargs.get(f\"cluster_{i}_radius_start\", 0)\n",
    "            cluster_radius_end = kwargs.get(f\"cluster_{i}_radius_end\", 50)\n",
    "\n",
    "            # Compute normalization terms\n",
    "            min_x = min(min_x, cluster_center_x - cluster_radius_end)\n",
    "            min_y = min(min_y, cluster_center_y - cluster_radius_end)\n",
    "\n",
    "            max_x = max(max_x, cluster_center_x + cluster_radius_end)\n",
    "            max_y = max(max_y, cluster_center_y + cluster_radius_end)\n",
    "\n",
    "            # Generate the needed points\n",
    "            for j in range(kwargs.get(f\"cluster_{i}_size\", 15)):\n",
    "                angle = np.deg2rad(np.random.uniform(cluster_angle_start, cluster_angle_end))\n",
    "                radius = np.random.uniform(cluster_radius_start, cluster_radius_end)\n",
    "                x = cluster_center_x + radius * np.cos(angle)\n",
    "                y = cluster_center_y + radius * np.sin(angle)\n",
    "                current_cluster.append(DataPoint(x, y, original_cluster=i - 1, cluster=i - 1))\n",
    "\n",
    "            clusters.append(current_cluster)\n",
    "\n",
    "        return Dataset(_clusters=clusters, min_x=min_x, min_y=min_y, max_x=max_x, max_y=max_y)\n",
    "\n",
    "    @property\n",
    "    def distance_matrix(self) -> np.array:\n",
    "        \"\"\"\n",
    "        Distance matrix[i][j] = distance between i and j\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.cached_distance_matrix is not None:\n",
    "            return self.cached_distance_matrix\n",
    "        complete_dataset: List[DataPoint] = self.complete_dataset\n",
    "        dataset_size = len(complete_dataset)\n",
    "        distance_matrix = np.zeros(shape=(dataset_size, dataset_size))\n",
    "        for i in range(dataset_size):\n",
    "            for j in range(dataset_size):\n",
    "                distance_matrix[i][j] = complete_dataset[i].dist(complete_dataset[j])\n",
    "        self.cached_distance_matrix = distance_matrix\n",
    "        return distance_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def blobs(cluster_1_size=100, cluster_2_size=100) -> \"Dataset\":\n",
    "        \"\"\"Generates points in blobs around the 20 and 80 point\"\"\"\n",
    "        return Dataset.gen_clusters(\n",
    "            clusters=2,\n",
    "            cluster_1_size=cluster_1_size,\n",
    "            cluster_1_center_x=20,\n",
    "            cluster_1_center_y=50,\n",
    "            cluster_1_radius_end=20,\n",
    "\n",
    "            cluster_2_size=cluster_2_size,\n",
    "            cluster_2_center_x=80,\n",
    "            cluster_2_center_y=50,\n",
    "            cluster_2_radius_end=20\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def concave_clusters(cluster_1_size=100, cluster_2_size=100) -> \"Dataset\":\n",
    "        return Dataset.gen_clusters(clusters=2,\n",
    "                                    cluster_1_size=cluster_1_size,\n",
    "                                    cluster_1_angle_start=0, cluster_1_angle_end=180,\n",
    "                                    cluster_1_center_x=45, cluster_1_center_y=50,\n",
    "                                    cluster_1_radius_start=8, cluster_1_radius_end=10,\n",
    "\n",
    "                                    cluster_2_size=cluster_2_size,\n",
    "                                    cluster_2_angle_start=180, cluster_2_angle_end=360,\n",
    "                                    cluster_2_center_x=55, cluster_2_center_y=50,\n",
    "                                    cluster_2_radius_start=8, cluster_2_radius_end=10, )\n",
    "\n",
    "    def plot(self, initial=False):\n",
    "        clusters = [list() for i in self._clusters]\n",
    "        for i in self.complete_dataset:\n",
    "            clusters[i.cluster if not initial else i.original_cluster].append(i)\n",
    "\n",
    "        for cluster in clusters:\n",
    "            plt.scatter(\n",
    "                [point.x for point in cluster],\n",
    "                [point.y for point in cluster]\n",
    "            )\n",
    "\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also implement the ```map``` function, that can be used to map Data Points onto the Bloch Sphere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(a: float, b: float, c: float, d: float, e: float) -> float:\n",
    "    return d + ((a - b) / (c - b)) * (e - d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qiskit\n",
    "Now, we start working with Qiskit! Import all the necessary elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qiskit import Aer\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import transpile\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.quantum_info import state_fidelity\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = Dataset.blobs(100, 100)\n",
    "dataset.plot()\n",
    "dataset.distance_matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fix the np random seed\n",
    "np.random.seed(12)\n",
    "\n",
    "#\n",
    "# Hard-code the data points that the algorithm will be performed on\n",
    "#\n",
    "\n",
    "# Hard-code the two reference states on the bloch-sphere that we will use as references for two clusters\n",
    "#\n",
    "# [1, 0] = |0> and [0, 1] = |1>\n",
    "reference_points = [[1, 0], [0, 1]]\n",
    "\n",
    "circuit_counter = 0\n",
    "\n",
    "\n",
    "# Function: setup the variational form according to given parameters\n",
    "\n",
    "\n",
    "def setup_variational_form(dp: DataPoint, params) -> QuantumCircuit:\n",
    "    global circuit_counter\n",
    "\n",
    "    q_circuit = QuantumCircuit(1)\n",
    "    q_circuit.name = \"circuit\" + str(circuit_counter)\n",
    "    circuit_counter += 1\n",
    "    q_circuit.initialize([1, 0], 0)\n",
    "\n",
    "    q_circuit.u(\n",
    "        map(dp.x, 0, 1, 0, math.pi),\n",
    "        map(dp.y, 0, 1, 0, math.pi),\n",
    "        0,\n",
    "        0\n",
    "    )\n",
    "    q_circuit.u(params[0], params[1], 0, 0)\n",
    "\n",
    "    #print(\"Quantum Circuit:\")\n",
    "    #print(q_circuit)\n",
    "\n",
    "    q_circuit.save_statevector()\n",
    "\n",
    "    return q_circuit\n",
    "\n",
    "\n",
    "#setup_variational_form(DataPoint(0, 0), [0, 0])\n",
    "\n",
    "qiskit_backend = Aer.get_backend(\"aer_simulator\")\n",
    "\n",
    "\n",
    "def run_circuit_for_point(data_points, data_point_index: int, params):\n",
    "    return qiskit_backend.run(\n",
    "        transpile(\n",
    "            setup_variational_form(data_points[data_point_index], params),\n",
    "            backend=qiskit_backend\n",
    "        )\n",
    "    ).result().get_statevector()\n",
    "\n",
    "\n",
    "def objective_function_with_datapoints(data_points: Dataset):\n",
    "    def objective(params) -> float:\n",
    "\n",
    "        state_lambda = lambda x: run_circuit_for_point(data_points, x, params)\n",
    "\n",
    "        n = len(data_points)\n",
    "        m = len(reference_points)\n",
    "        # Computing state fidelity\n",
    "        state_cache = [state_lambda(i) for i in tqdm(range(n))]\n",
    "        # Computing the fidelity matrix f(i, a) = fidelity between datapoint i and reference a\n",
    "        fidelity_matrix = np.zeros(shape=(n, m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                fidelity_matrix[i][j] = state_fidelity(state_cache[i], reference_points[j])\n",
    "\n",
    "        # Computing the fidelity matrix f(i, j) = sum over all references [ f(i, a) * f(j, a) ]\n",
    "        fidelity_sum_matrix = np.zeros(shape=(n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if i == j: continue\n",
    "                if j < i:\n",
    "                    fidelity_sum_matrix[i][j] = fidelity_sum_matrix[j][i]\n",
    "                else:\n",
    "                    fidelity_sum = np.dot(fidelity_matrix[i, :], fidelity_matrix[j, :])\n",
    "                    fidelity_sum_matrix[i][j] = fidelity_sum\n",
    "\n",
    "        # Cost function = sum over all distance[i][j] * fidelity_sum_matrix[i][j]\n",
    "        cost = np.sum(np.multiply(data_points.distance_matrix, fidelity_sum_matrix))\n",
    "        return cost\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "# Select the right optimizer\n",
    "optimizer = SPSA(maxiter=2)\n",
    "\n",
    "\n",
    "def cluster_dataset(dataset: Dataset):\n",
    "    # Initialize the parameters with random values\n",
    "    params_init = np.random.rand(2)\n",
    "    fun = objective_function_with_datapoints(dataset)\n",
    "    # Perform the optimization and store the result\n",
    "    optimal_params = optimizer.minimize(fun=fun, x0=params_init).x\n",
    "\n",
    "    print(optimal_params)\n",
    "    print(\"Total cost: \" + str((fun(optimal_params))))\n",
    "\n",
    "    n = len(dataset)\n",
    "    m = len(reference_points)\n",
    "    state_vectors = [run_circuit_for_point(dataset, i, optimal_params) for i in range(n)]\n",
    "    fidelity_matrix = np.zeros(shape=(n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            fidelity_matrix[i][j] = state_fidelity(state_vectors[i], reference_points[j])\n",
    "\n",
    "    cluster_iter = iter(np.argmax(fidelity_matrix, axis=1))\n",
    "    for i in dataset.complete_dataset:\n",
    "        i.cluster = next(cluster_iter)\n",
    "    dataset.plot(initial=True)\n",
    "    dataset.plot()\n",
    "    print(f\"Accuracy: {dataset.accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_dataset(Dataset.blobs(100, 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_dataset(Dataset.concave_clusters(100, 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
